sudo /home/puc/kafka_2.11-1.0.0/bin/kafka-server-start.sh /home/puc/kafka_2.11-1.0.0/config/server.properties
this first command executes the server of kafka localy (no cluster). It must be keep opened

sudo /home/puc/kafka_2.11-1.0.0/bin/kafka-topics.sh --create --zookeeper localhost: 2181 --replication-factor 1 --partitions 1 --topic ead-puc
creating a topic on kafka

sudo /home/puc/kafka_2.11-1.0.0/bin/kafka-topics.sh --list --zookeeper localhost: 2181
this cmd shows the topics already created

sudo /home/puc/kafka_2.11-1.0.0/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic ead-puc
This cmd uses the producer command which create topics on Kafka

sudo /home/puc/kafka_2.11-1.0.0/bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic ead-puc --from-beginning
this cmd consumes the topic added on kafka from the beginning

Reading scripts to achieve <flafka>

flume-ng agent --conf-file spool-to-logger.properties --name agent1 -Dflume.root.logger=WARN,console
spool-to-logger is name of the file wich contains the agent name. In this case agent1

flume-ng agent --conf-file spool-to-kafka.properties --name agent2 -Dflume.root.logger=WARN,console
Now I using this cmd to add topics from a file on consumer

Done

flume-ng agent --conf-file twitter.properties --name agent3 -Dflume.root.logger=WARN,console

sudo /home/puc/kafka_2.11-1.0.0/bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic twittertopic --from-beginning

How to read twitter data with kafla and flume?

flume-ng agent --conf-file twitter.properties --name agent3 -Dflume.root.logger=WARN,console

sudo /home/puc/kafka_2.11-1.0.0/bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic twittertopic --from-beginning

Execute these both commands

The agent3 is te name of an agent in a file on my pc

twitter.properties is the name of the file
